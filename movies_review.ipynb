{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load dataset \n",
    "df = pd.read_csv('/content/drive/MyDrive/MSc. DSA/Module V/DSA 8501 Text and Unstructured Data Analytics/tmdb_5000_movies.csv.gz')  \n",
    "\n",
    "# Display first few rows\n",
    "display(df.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Print the columns in the dataframe\n",
    "print(df.columns)\n",
    "\n",
    "# Replace this with your actual sentiment analysis logic\n",
    "df['sentiment'] = np.random.choice(['positive', 'negative'], size=len(df)) \n",
    "\n",
    "# Plot sentiment distribution with labels\n",
    "plt.figure(figsize=(6,4))\n",
    "ax = sns.countplot(x='sentiment', data=df, palette='coolwarm')\n",
    "plt.title(\"Sentiment Distribution\")\n",
    "plt.xlabel(\"Sentiment\")\n",
    "plt.ylabel(\"Count\")\n",
    "\n",
    "# Add text labels\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width()/2., p.get_height()), \n",
    "                ha='center', va='baseline', fontsize=12, color='black', xytext=(0,5), \n",
    "                textcoords='offset points')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Preprocess text\n",
    "def clean_text(text):\n",
    "    # Check if the input is a string\n",
    "    if isinstance(text, str):\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'[^a-zA-Z0-9]', ' ', text)\n",
    "        text = ' '.join([word for word in text.split() if word not in stopwords.words('english')])\n",
    "        return text\n",
    "    # This will ensure that if its not a string then return it as is or handle it appropriately \n",
    "    else:\n",
    "        return str(text)\n",
    "\n",
    "df['cleaned_overview'] = df['overview'].apply(clean_text)\n",
    "\n",
    "# Generate WordCloud\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(' '.join(df['cleaned_overview']))\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Word Cloud of Movie Reviews\")\n",
    "plt.show()\n",
    "\n",
    "# Analyze Word Frequency\n",
    "all_words = ' '.join(df['cleaned_overview']).split()\n",
    "word_freq = Counter(all_words)\n",
    "most_common_words = word_freq.most_common(20)\n",
    "\n",
    "# Convert to DataFrame for visualization\n",
    "word_freq_df = pd.DataFrame(most_common_words, columns=['Word', 'Frequency'])\n",
    "\n",
    "# Plot most common words\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.barplot(x='Frequency', y='Word', data=word_freq_df, palette='viridis')\n",
    "plt.title(\"Top 20 Most Common Words in Reviews\")\n",
    "plt.xlabel(\"Frequency\")\n",
    "plt.ylabel(\"Words\")\n",
    "plt.show()\n",
    "\n",
    "# Convert sentiment labels to binary (0 = negative, 1 = positive)\n",
    "df['sentiment'] = df['sentiment'].map({'negative': 0, 'positive': 1})\n",
    "\n",
    "# Split dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['cleaned_overview'], df['sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert text data into numerical format using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Train Naïve Bayes Model\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_tfidf, y_train)\n",
    "nb_predictions = nb_model.predict(X_test_tfidf)\n",
    "\n",
    "# Train Logistic Regression Model\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "lr_model.fit(X_train_tfidf, y_train)\n",
    "lr_predictions = lr_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate models\n",
    "def evaluate_model(model_name, y_true, y_pred):\n",
    "    print(f\"{model_name} Performance:\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_true, y_pred):.4f}\")\n",
    "    print(f\"Precision: {precision_score(y_true, y_pred):.4f}\")\n",
    "    print(f\"Recall: {recall_score(y_true, y_pred):.4f}\")\n",
    "    print(f\"F1 Score: {f1_score(y_true, y_pred):.4f}\")\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred))\n",
    "    print(\"-\"*50)\n",
    "\n",
    "# Display evaluation results\n",
    "evaluate_model(\"Naïve Bayes\", y_test, nb_predictions)\n",
    "evaluate_model(\"Logistic Regression\", y_test, lr_predictions)\n",
    "# Visualize the performance of both models\n",
    "plt.figure(figsize=(10, 5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
